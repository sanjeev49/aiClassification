{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "root_dir = os.getcwd()\n",
    "artifacts_dir = os.path.join(root_dir, \"artifacts\")\n",
    "data_dir = os.path.join(artifacts_dir, \"data_dir\")\n",
    "\n",
    "X = os.path.join(data_dir, \"X.pickle\")\n",
    "y = os.path.join(data_dir, \"y.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "challenge_dir = os.path.join(root_dir, \"Multilabel\")\n",
    "img_dir = os.path.join(challenge_dir, \"photos\")\n",
    "print(os.path.exists(img_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.applications.vgg16 import decode_predictions\n",
    "from keras.applications.regnet import preprocess_input\n",
    "import tensorflow as tf\n",
    "from keras.utils import load_img\n",
    "import matplotlib.pyplot as plt \n",
    "from PIL import Image \n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os \n",
    "from tensorflow.keras.models import Sequential\n",
    "#tf.keras.utils.img_to_array \n",
    "from tensorflow.keras.utils import img_to_array\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = pickle.load(open(X, \"rb\"))\n",
    "y = pickle.load(open(y, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = []\n",
    "\n",
    "def _load_image(img_dir):\n",
    "    for num, img in enumerate(os.listdir(img_dir)):\n",
    "        img_path = os.path.join(img_dir, img)\n",
    "        im = load_img(img_path, target_size = (224, 224,3))\n",
    "        im = img_to_array(im)\n",
    "        #im  = np.expand_dims(im, axis =0)\n",
    "        #print(im.shape)\n",
    "        im = preprocess_input(im)\n",
    "        #print(im.shape)\n",
    "        raw_data.append([im, [y[num][0], y[num][1], y[num][2],y[num][3]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_load_image(img_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for i,data in enumerate(raw_data):\n",
    "    X.append(raw_data[i][0])\n",
    "    y.append(raw_data[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(y)\n",
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b,c, d = [], [] , [], []\n",
    "for i in y:\n",
    "    a.append(i[0]), b.append(i[1]), c.append(i[2]), d.append(i[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(a)\n",
    "b = np.array(b)\n",
    "c = np.array(c)\n",
    "d = np.array(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = tf.keras.applications.ResNet50(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape = (224,224,3),\n",
    "    pooling=None,\n",
    "    classes = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in resnet.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_a = Input(shape=(224,224, 3))\n",
    "col_b = Input(shape=(224,224, 3))\n",
    "col_c = Input(shape=(224,224, 3))\n",
    "col_d = Input(shape=(224,224, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_a_feature = resnet(col_a)\n",
    "col_b_feature = resnet(col_b)\n",
    "col_c_feature = resnet(col_c)\n",
    "col_d_feature=   resnet(col_d)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_feature = layers.concatenate([col_a_feature, col_b_feature,col_c_feature, col_d_feature], axis =-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = layers.Dense(1, activation='sigmoid')(merged_feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([col_a, col_b, col_c, col_d], predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = [\"categorical_crossentropy\", \"categorical_crossentropy\", \"categorical_crossentropy\", \"categorical_crossentropy\"], optimizer= \"adam\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.compile(loss = \"categorical_crossentropy\", optimizer= \"adam\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet.compile(loss=[['categorical_crossentropy', 'categorical_crossentropy', 'categorical_crossentropy', 'categorical_crossentropy']], optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 167s 7s/step - loss: 2.0437 - accuracy: 0.2707 - val_loss: 1.8914 - val_accuracy: 0.2931\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X , y, validation_split=0.2, epochs=1, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = load_img(r\"Multilabel\\photos\\image_005.jpg\", target_size = (224, 224,3))\n",
    "im = img_to_array(im)\n",
    "        #im  = np.expand_dims(im, axis =0)\n",
    "        #print(im.shape)\n",
    "im = preprocess_input(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = im.reshape(1, im.shape[0], im.shape[1],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 981ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.99950236]], dtype=float32)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001FBD7B27790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    }
   ],
   "source": [
    "li = [model1, model2, model3, model4]\n",
    "a = []\n",
    "for i in li:\n",
    "    a.append(i.predict(im))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.99950236]], dtype=float32),\n",
       " array([[0.9988428]], dtype=float32),\n",
       " array([[0.00166525]], dtype=float32),\n",
       " array([[0.00105461]], dtype=float32)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2212629649.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [102]\u001b[1;36m\u001b[0m\n\u001b[1;33m    if (i[0][0]=>0.5):\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "for i in a:\n",
    "    if (i[0][0]=>0.5):\n",
    "        result.append(1)\n",
    "    else:\n",
    "        result.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Functional' from 'tensorflow.keras.models' (c:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\api\\_v2\\keras\\models\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sanjeev\\Documents\\Image_attribute_classification\\experiment2.ipynb Cell 43\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sanjeev/Documents/Image_attribute_classification/experiment2.ipynb#ch0000067?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Functional\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'Functional' from 'tensorflow.keras.models' (c:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\api\\_v2\\keras\\models\\__init__.py)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = tf.keras.layers.Input(shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st layer as the lumpsum weights from resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
    "# NOTE that this layer will be set below as NOT TRAINABLE, i.e., use it as is\n",
    "resnet_in =  tf.keras.applications.ResNet50(include_top = False, pooling = 'avg', weights = 'imagenet')(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet_in.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet_in = tf.keras.layers.Input((resnet_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Output tensors of a Functional model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: <keras.layers.core.dense.Dense object at 0x000001FB63409BE0>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sanjeev\\Documents\\Image_attribute_classification\\experiment2.ipynb Cell 48\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sanjeev/Documents/Image_attribute_classification/experiment2.ipynb#ch0000062?line=9'>10</a>\u001b[0m out_3 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m1\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sanjeev/Documents/Image_attribute_classification/experiment2.ipynb#ch0000062?line=10'>11</a>\u001b[0m out_4 \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m1\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/sanjeev/Documents/Image_attribute_classification/experiment2.ipynb#ch0000062?line=12'>13</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mModel(inputs \u001b[39m=\u001b[39;49m [input_img], outputs\u001b[39m=\u001b[39;49m[out_1, out_2, out_3, out_4])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/sanjeev/Documents/Image_attribute_classification/experiment2.ipynb#ch0000062?line=14'>15</a>\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m[tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mBinaryCrossentropy(), tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mBinaryCrossentropy(), tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mBinaryCrossentropy(), tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlosses\u001b[39m.\u001b[39mBinaryCrossentropy()], optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    586\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 587\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    588\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    589\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\functional.py:148\u001b[0m, in \u001b[0;36mFunctional.__init__\u001b[1;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mall\u001b[39m([functional_utils\u001b[39m.\u001b[39mis_input_keras_tensor(t)\n\u001b[0;32m    146\u001b[0m               \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(inputs)]):\n\u001b[0;32m    147\u001b[0m     inputs, outputs \u001b[39m=\u001b[39m functional_utils\u001b[39m.\u001b[39mclone_graph_nodes(inputs, outputs)\n\u001b[1;32m--> 148\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_graph_network(inputs, outputs)\n",
      "File \u001b[1;32mc:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\tensorflow\\python\\training\\tracking\\base.py:587\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    586\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 587\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    588\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    589\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\functional.py:186\u001b[0m, in \u001b[0;36mFunctional._init_graph_network\u001b[1;34m(self, inputs, outputs)\u001b[0m\n\u001b[0;32m    183\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(tensor, \u001b[39m'\u001b[39m\u001b[39m_keras_history\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutputs):\n\u001b[0;32m    184\u001b[0m     base_layer_utils\u001b[39m.\u001b[39mcreate_keras_history(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_nested_outputs)\n\u001b[1;32m--> 186\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_graph_inputs_and_outputs()\n\u001b[0;32m    188\u001b[0m \u001b[39m# A Network does not create weights of its own, thus it is already\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[39m# built.\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuilt \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\functional.py:740\u001b[0m, in \u001b[0;36mFunctional._validate_graph_inputs_and_outputs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m'\u001b[39m\u001b[39m_keras_history\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m    739\u001b[0m   cls_name \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\n\u001b[1;32m--> 740\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mOutput tensors of a \u001b[39m\u001b[39m{\u001b[39;00mcls_name\u001b[39m}\u001b[39;00m\u001b[39m model must be \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    741\u001b[0m                    \u001b[39m'\u001b[39m\u001b[39mthe output of a TensorFlow `Layer` \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    742\u001b[0m                    \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m(thus holding past layer metadata). Found: \u001b[39m\u001b[39m{\u001b[39;00mx\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: Output tensors of a Functional model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: <keras.layers.core.dense.Dense object at 0x000001FB63409BE0>"
     ]
    }
   ],
   "source": [
    "# model = Sequential()\n",
    "\n",
    "\n",
    "# # Say not to train first layer (ResNet) model as it is already trained\n",
    "# resnet_in.layers[0].trainable = False\n",
    "\n",
    "# 2nd layer as Dense for 2-class classification, i.e., dog or cat using SoftMax activation\n",
    "out_1 = tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "out_2 = tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "out_3 = tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "out_4 = tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "\n",
    "model = tf.keras.Model(inputs = [input_img], outputs=[out_1, out_2, out_3, out_4])\n",
    "\n",
    "model.compile(loss=[tf.keras.losses.BinaryCrossentropy(), tf.keras.losses.BinaryCrossentropy(), tf.keras.losses.BinaryCrossentropy(), tf.keras.losses.BinaryCrossentropy()], optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50 (Functional)       (None, 2048)              23587712  \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 4)                 8196      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,595,908\n",
      "Trainable params: 8,196\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:1082: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\losses.py\", line 1930, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"c:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\backend.py\", line 5283, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 1) vs (None, 4)).\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\sanjeev\\Documents\\Image_attribute_classification\\experiment2.ipynb Cell 45\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/sanjeev/Documents/Image_attribute_classification/experiment2.ipynb#ch0000064?line=0'>1</a>\u001b[0m model1\u001b[39m.\u001b[39;49mfit(X, y , epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m64\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filekym96atu.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"c:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\losses.py\", line 139, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\losses.py\", line 243, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\losses.py\", line 1930, in binary_crossentropy\n        backend.binary_crossentropy(y_true, y_pred, from_logits=from_logits),\n    File \"c:\\Users\\sanjeev\\miniconda3\\envs\\deep_learning\\lib\\site-packages\\keras\\backend.py\", line 5283, in binary_crossentropy\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)\n\n    ValueError: `logits` and `labels` must have the same shape, received ((None, 1) vs (None, 4)).\n"
     ]
    }
   ],
   "source": [
    "model1.fit(X, y , epochs=1, validation_split=0.2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 0],\n",
       "       [1, 1, 0, 0],\n",
       "       [1, 1, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 0, 0],\n",
       "       [1, 1, 0, 0],\n",
       "       [1, 1, 0, 0]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('deep_learning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "291713af647146e04ac219d946794240e5391d23bed4a06bbd169cf4cac42e79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
